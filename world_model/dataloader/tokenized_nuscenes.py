import json
import pickle
from typing import Any, Dict, Optional, List, Union

import numpy as np
from torch.utils.data import DataLoader, default_collate
from lightning import LightningDataModule

from world_model.dataloader.components.tokenized_nuscenes import TokenizedNuScenesDataset


# overrinding default_collate for list of strings (e.g., list of image paths).
def custom_collate(batch_items):

    special_dict = {}
    keys = ['images_paths', 'scene_names']
    for key in keys:
        # Extract 'key' for special processing and remove from original batch dict
        value = [item[key] for item in batch_items]
        special_dict[key] = value
        for item in batch_items:
            del item[key]

    # Use default_collate for other fields
    batch = default_collate(batch_items)

    # When available, context_end_index is an integer indicating which frames in the sequence
    # are part of the context. It is the same for all elements of the batch
    if 'context_end_index' in batch:
        batch['context_end_index'] = batch['context_end_index'][0]

    # And put back the the specially processed entries
    batch = {**batch, **special_dict}

    return batch


def worker_rnd_init(x):
    np.random.seed(13 + x)


class TokenizedNuScenesDataModule(LightningDataModule):
    """
    LightningDataModule for the NuScenes dataset.

    A `LightningDataModule` implements:
        - prepare_data : things to do on 1 GPU/TPU, NOT on every GPU/TPU in DDP (download data, split, ...).
        - setup : things to do on every process in DDP (load data, set variables, ...)
        - train_dataloader : the training dataloader
        - val_dataloader : the validation dataloader
        - test_dataloader : the test dataloader
        - predict_dataloader : if a specific dataloader is needed at inference
        - teardown : called on every process in DDP after fit or test if clean up is needed

    This allows you to share a full dataset with a common structure and reduce writing of boilerplate code.

    Read the docs:
        https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html
    """

    def __init__(
        self,
        pickle_path: str,
        dataloader_params: Dict,
        quantized_visual_tokens_root_dir: str,
        sequence_length: int = 1,
        prediction_length: int = 0,
        subsampling_factor: int = 1,
        camera: Union[List[str], str] = 'CAM_FRONT',
        quantized_trajectory_root_dir: Optional[str] = None,
        command_db_path: Optional[str] = None,
    ) -> None:
        """
        Args:
            pickle_path: Path to the pickle file generated by `gen_nuplan_pickle.py` (see project's README).
            dataloader_params: A dict containing the dataloader-specific parameters (batch size, )
            quantized_visual_tokens_root_dir: The directory where quantized representations of the NuScenes images are stored.
            sequence_length: The number of consecutive frames to include in each data sample. Defaults to 1.
            prediction_length: The number of frames to predict in the future. Defaults to 0.
            subsampling_factor: only keep one frame every `subsampling_factor` frames.
            camera: Name of the camera to extract data for (e.g., 'CAM_F0', 'CAM_FRONT' this is dataset dependant)
            quantized_trajectory_root_dir: The directory where quantized representations of the NuScenes trajectory are stored.
            command_db_path: Path to the JSON file containing the command for each frame in the dataset.
        """
        super().__init__()

        # this line allows to access init params with 'self.hparams' attribute
        # also ensures init params will be stored in ckpt
        self.save_hyperparameters(logger=False)

        self.pickle_path = pickle_path
        self.command_db_path = command_db_path

        self.dataloader_params = dataloader_params
        dataset_params = {
            'quantized_visual_tokens_root_dir': quantized_visual_tokens_root_dir,
            'sequence_length': sequence_length,
            'prediction_length': prediction_length,
            'subsampling_factor': subsampling_factor,
            'camera': camera,
            'quantized_trajectory_root_dir': quantized_trajectory_root_dir,
        }
        self.train_dataset_params = dataset_params
        self.val_dataset_params = dataset_params

    def setup(self, stage: Optional[str] = None) -> "TokenizedNuScenesDataModule":
        """Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.

        This method is called by Lightning before `trainer.fit()`, `trainer.validate()`, `trainer.test()`, and
        `trainer.predict()`, so be careful not to execute things like random split twice!

        Args:
            stage: The stage to setup. Either `"fit"`, `"validate"`, `"test"`, or `"predict"`. Defaults to ``None``.
        """

        with open(self.pickle_path, "rb") as f:
            pickle_data = pickle.load(f)
        train_pickle_data, val_pickle_data = pickle_data['train'], pickle_data['val']

        command_db = None
        if self.command_db_path is not None:
            with open(self.command_db_path) as f:
                command_db = json.load(f)

        # Training dataset
        self.train_dataset = TokenizedNuScenesDataset(
            pickle_data=train_pickle_data,
            command_db=command_db,
            **self.train_dataset_params
        )

        # Validation dataset
        self.val_dataset = TokenizedNuScenesDataset(
            pickle_data=val_pickle_data,
            command_db=command_db,
            **self.val_dataset_params
        )

        return self

    def train_dataloader(self) -> DataLoader[Any]:
        """
        Create and return the train dataloader.
        """

        # Define default data shuffle if not set in config
        dataloader_params = self.dataloader_params.copy()
        if 'shuffle' not in dataloader_params:
            dataloader_params['shuffle'] = True

        return DataLoader(
            self.train_dataset,
            drop_last=True,
            worker_init_fn=worker_rnd_init,
            collate_fn=custom_collate,
            **dataloader_params
        )

    def val_dataloader(self) -> DataLoader[Any]:
        """
        Create and return the validation dataloader.
        """

        # Define default data shuffle if not set in config
        dataloader_params = self.dataloader_params.copy()
        if 'shuffle' not in dataloader_params:
            dataloader_params['shuffle'] = False

        return DataLoader(
            self.val_dataset,
            worker_init_fn=worker_rnd_init,
            collate_fn=custom_collate,
            **dataloader_params
        )

    def test_dataloader(self) -> DataLoader[Any]:
        """
        Create and return the test dataloader.
        """
        pass


if __name__ == '__main__':
    """
    Debug script to test the TokenizedNuScenesDataModule.

    srun -A ycy@h100 -C h100 --pty --nodes=1 \
    --ntasks-per-node=1 --cpus-per-task=16 \
    --gres=gpu:0 --hint=nomultithread \
    --qos=qos_gpu_h100-dev --time=01:00:00 \
    python world_model/dataloader/tokenized_nuscenes.py

    """
    import os

    from tqdm import tqdm

    _path = lambda x: os.path.expanduser(os.path.expandvars(x))

    pickle_path = os.path.join(_path('$ycy_ALL_CCFRSCRATCH'), 'nuscenes_cvpr', 'trainval_data.pkl')
    command_db_path = os.path.join(
        _path('$ycy_ALL_CCFRSCRATCH'),
        'nuscenes_cvpr',
        'nuscenes_commands.json',
    )
    visual_tokens_paths = os.path.join(
        _path('$ycy_ALL_CCFRSCRATCH'),
        'nuscenes_tokenized',
        'VQ_ds16_16384_llamagen',
    )
    trajectory_tokens_paths = os.path.join(
        _path('$ycy_ALL_CCFRSCRATCH'),
        'nuscenes_tokenized',
        'TrajectoryFSQ_seqlen6',
        'epoch_029_val_recon_loss_0.0211',
    )

    dataloader_params = {
        'batch_size': 16,
        'num_workers': 4,
        'pin_memory': True,
    }

    dm = TokenizedNuScenesDataModule(
        pickle_path=pickle_path,
        dataloader_params=dataloader_params,
        quantized_visual_tokens_root_dir=visual_tokens_paths,
        sequence_length=3,
        prediction_length=6,
        subsampling_factor=1,
        camera=['CAM_FRONT'],
        quantized_trajectory_root_dir=None,
        command_db_path=command_db_path,
    ).setup()

    for loader in [dm.train_dataloader(), dm.val_dataloader()]:
        for i, batch in enumerate(tqdm(loader)):
            if i == 0:
                print(batch.keys())
                print(batch['visual_tokens'].shape)
                print(batch['timestamps'].shape)
                print(batch['commands'].shape)
            pass
