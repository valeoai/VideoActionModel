import pickle
from pathlib import Path
from typing import Any, Callable, Dict, Optional

import numpy as np
from lightning import LightningDataModule
from torch.utils.data import DataLoader, default_collate

from world_model.utils.cmd_line_logging import RankedLogger
from world_model.dataloader.components.random_tokenized_sequence_nuplan import RandomTokenizedSequenceNuplanDataset

log = RankedLogger(__name__, rank_zero_only=True)


# overrinding default_collate for list of strings (e.g., list of image paths).
def custom_collate(batch_items):

    special_dict = {}
    keys = ['images_paths', 'scene_names']
    for key in keys:
        # Extract 'key' for special processing and remove from original batch dict
        value = [item[key] for item in batch_items]
        special_dict[key] = value
        for item in batch_items:
            del item[key]

    # Use default_collate for other fields
    batch = default_collate(batch_items)

    # When available, context_end_index is an integer indicating which frames in the sequence
    # are part of the context. It is the same for all elements of the batch
    if 'context_end_index' in batch:
        batch['context_end_index'] = batch['context_end_index'][0]

    # And put back the the specially processed entries
    batch = {**batch, **special_dict}

    return batch


def worker_rnd_init(x):
    np.random.seed(13 + x)


class TokenizedSequenceNuplanDataModule(LightningDataModule):
    """
    LightningDataModule for the nuPlan dataset.

    A `LightningDataModule` implements:
        - prepare_data : things to do on 1 GPU/TPU, NOT on every GPU/TPU in DDP (download data, split, ...).
        - setup : things to do on every process in DDP (load data, set variables, ...)
        - train_dataloader : the training dataloader
        - val_dataloader : the validation dataloader
        - test_dataloader : the test dataloader
        - predict_dataloader : if a specific dataloader is needed at inference
        - teardown : called on every process in DDP after fit or test if clean up is needed

    This allows you to share a full dataset with a common structure and reduce writing of boilerplate code.

    Read the docs:
        https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html
    """

    def __init__(
        self,
        pickle_path: str,
        train_pickle_name: str,
        val_pickle_name: str,
        dataloader_params: Dict,
        train_dataset_params: Dict,
        val_dataset_params: Dict,
        transform: Optional[Callable] = None,
        **kwargs,
    ) -> None:
        """
        Args:
            pickle_path: Path to the pickle file generated by `gen_nuplan_pickle.py` (see project's README).
            dataloader_params: A dict containing the dataloader-specific parameters (batch size, )
            train_dataset_params: Parameters that will be transfered to the train dataset class
            val_dataset_params: Parameters that will be transfered to the validation dataset class
        """
        super().__init__()

        # this line allows to access init params with 'self.hparams' attribute
        # also ensures init params will be stored in ckpt
        self.save_hyperparameters(logger=False)

        pickle_path = Path(pickle_path)

        self.train_pickle_path = pickle_path / train_pickle_name
        self.val_pickle_path = pickle_path / val_pickle_name

        self.transform = transform

        self.dataloader_params = dataloader_params
        self.train_dataset_params = train_dataset_params
        self.val_dataset_params = val_dataset_params

    def setup(self, stage: Optional[str] = None) -> None:
        """Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.

        This method is called by Lightning before `trainer.fit()`, `trainer.validate()`, `trainer.test()`, and
        `trainer.predict()`, so be careful not to execute things like random split twice!

        Args:
            stage: The stage to setup. Either `"fit"`, `"validate"`, `"test"`, or `"predict"`. Defaults to ``None``.
        """
        log.info("Loading training data...")
        with open(self.train_pickle_path, "rb") as f:
            self.train_data = pickle.load(f)

        log.info("Loading val data...")
        with open(self.val_pickle_path, "rb") as f:
            self.val_data = pickle.load(f)

        # Training dataset
        log.info("Creating training dataset...")
        self.train_dataset = RandomTokenizedSequenceNuplanDataset(
            pickle_data=self.train_data,
            transform=self.transform,
            **self.train_dataset_params
        )

        # Validation dataset
        log.info("Creating training dataset...")
        self.val_dataset = RandomTokenizedSequenceNuplanDataset(
            pickle_data=self.val_data,
            transform=self.transform,
            **self.val_dataset_params
        )

    def train_dataloader(self) -> DataLoader[Any]:
        """
        Create and return the train dataloader.
        """

        # Define default data shuffle if not set in config
        dataloader_params = self.dataloader_params.copy()
        if 'shuffle' not in dataloader_params:
            dataloader_params['shuffle'] = True

        return DataLoader(
            self.train_dataset,
            drop_last=True,
            worker_init_fn=worker_rnd_init,
            collate_fn=custom_collate,
            **dataloader_params
        )

    def val_dataloader(self) -> DataLoader[Any]:
        """
        Create and return the validation dataloader.
        """

        # Define default data shuffle if not set in config
        dataloader_params = self.dataloader_params.copy()
        if 'shuffle' not in dataloader_params:
            dataloader_params['shuffle'] = False

        return DataLoader(
            self.val_dataset,
            worker_init_fn=worker_rnd_init,
            collate_fn=custom_collate,
            **dataloader_params
        )

    def test_dataloader(self) -> DataLoader[Any]:
        """
        Create and return the test dataloader.
        """
        pass
