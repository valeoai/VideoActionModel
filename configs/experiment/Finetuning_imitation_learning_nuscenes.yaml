# @package _global_

defaults:
  - override /data: tokenized_with_action_nuscenes
  - override /model: next_token_predictor_imitation
  - override /model/network: mup_gpt2
  - override /model/sequence_adapter: gpt_adapter
  - override /callbacks: callbacks_nuscenes_finetuning
  - override /trainer: deepspeed2
  - override /logger: many_loggers
  - override /paths: jeanzay_nuplan
  - override /optimizer: muAdamW
  - override /scheduler: warmup_stable_drop


trainer:
  max_steps: 28 # one epoch is 10632 steps, if batch size = 384 --> ~27
  # clip gradients' global norm to using gradient_clip_algorithm='norm' by default
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  log_every_n_steps: 5

scheduler:
  warmup_iter: 0 # 1% ~ end_iter * 0.01
  end_iter: ${trainer.max_steps} # (len_dataset - 1) // BATCH_SIZE * nb_epochs
  drop_iter: ${scheduler.end_iter} # We are finetuning so we linearly decay the LR

data:
  pickle_path: /lustre/fsn1/projects/rech/ycy/commun/nuscenes_cvpr/trainval_data.pkl
  quantized_visual_tokens_root_dir: /lustre/fsn1/projects/rech/ycy/commun/nuscenes_tokenized/VQ_ds16_16384_llamagen
  quantized_trajectory_root_dir: /lustre/fsn1/projects/rech/ycy/commun/nuscenes_tokenized/TrajectoryFSQ_seqlen6/epoch_029_val_recon_loss_0.0315/
  command_db_path: /lustre/fsn1/projects/rech/ycy/commun/nuscenes_cvpr/nuscenes_commands.json
  sequence_length: 20
  trajectory_length: 6

# VQ_ds16_16384_llamagen/metadata.json indicates 18x32 quantized image features for nuplan
model:
  statedict_ckpt_path: "/lustre/fsn1/projects/rech/ycy/commun/output_data/opendv_GPT2_LlamaGen/large_scale/muP_GPT2_split_opendv_dim2048_part_3/checkpoints/end_of_epoch_epoch=002_step=0000149837_fused.pt"
  mup_base_shapes: ./mup_shapes/gpt2_24layers_nobias_basewidth128_with_commands.bsh
  network:
    embedding_dim: 128
    nb_heads: 1
    nb_layers: 24
    mlp_dim_mult: 4
    vocabulary_size: 18384 # 16384 + 1000 + 1000 | visual_vocab_size + sum(action_vocab_sizes)
    nb_timesteps: ${data.sequence_length}
    nb_tokens_per_timestep: 578 # 18*32 + 2 = 576 + 2 = 578| visual tokens + action embeddings 
    dropout_rate: 0.0
    init_std: 0.02
    bias: False
    output_tied: True
    output_scale: 1.0
    attn_scale: 1.0
    learnable_gains: False
    nb_commands: 3 # straight, left, right
  sequence_adapter:
    visual_vocab_size: 16384
    action_vocab_sizes:
      - 1000
      - 1000