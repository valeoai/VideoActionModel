services:
  ncap_renderer:
    image: ${RENDERING_IMAGE}
    container_name: ncap_renderer_${SCENARIO}_${SEQ}
    runtime: nvidia
    environment:
      - TORCH_HOME=${TORCH_HOME}
      - PYTHONPATH=.
    volumes:
      - ${RENDERING_FOLDER}:/neurad_studio
      - ${NUSCENES_PATH}:/neurad_studio/data/nuscenes
      - ${BASE_DIR}/.cache:${TORCH_HOME}
    working_dir: /neurad_studio
    ports:
      - "${RENDERER_PORT}:${RENDERER_PORT}"
    command: >
      python -u nerfstudio/scripts/closed_loop/main.py
      --port ${RENDERER_PORT}
      --load-config ${RENDERING_CHECKPOINTS_PATH}/${SEQ}/config.yml
      --adjust_pose
    shm_size: "40gb"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ["${NCAP_GPUS}"]

  ncap_model:
    image: ${MODEL_IMAGE}
    container_name: ncap_model_${SCENARIO}_${SEQ}
    runtime: nvidia
    environment:
      - TORCH_HOME=${TORCH_HOME}
      - PYTHONPATH=.
    volumes:
      - ${MODEL_FOLDER}:/model
      - ${BASE_DIR}/.cache:${TORCH_HOME}
      - ${IMAGE_TOKENIZER_PATH}:/model/weights/tokenizers/image_tokenizer.jit
      - ${TRAJECTORY_TOKENIZER_PATH}:/model/weights/tokenizers/trajectory_tokenizer.jit
      - ${WM_CKPT_PATH}:/model/weights/world_model/checkpoint.pt
      - ${WM_CONFIG_PATH}:/model/weights/world_model/config.yaml
    working_dir: /model
    ports:
      - "${MODEL_PORT}:${MODEL_PORT}"
    command: >
      python -u inference/server.py
      --port ${MODEL_PORT}
      --config_path ${MODEL_CFG_PATH}
      --checkpoint_path ${MODEL_CHECKPOINT_PATH}
    shm_size: "40gb"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ["${NCAP_GPUS}"]

  ncap_front:
    image: ${NCAP_IMAGE}
    container_name: ncap_front_${SCENARIO}_${SEQ}
    runtime: nvidia
    environment:
      - TORCH_HOME=${TORCH_HOME}
    volumes:
      - ${NCAP_FOLDER}:/neuro_ncap
      - ${NUSCENES_PATH}:/neuro_ncap/data/nuscenes
      - ${BASE_DIR}/.cache:${TORCH_HOME}
    working_dir: /neuro_ncap
    command: >
      python -u main.py
      --engine.renderer.host renderer
      --engine.renderer.port ${RENDERER_PORT}
      --engine.model.host model
      --engine.model.port ${MODEL_PORT}
      --engine.dataset.data_root /neuro_ncap/data/nuscenes
      --engine.dataset.version v1.0-trainval
      --engine.dataset.sequence ${SEQ}
      --engine.logger.log-dir /neuro_ncap/${LOG_DIR}/${TIME_NOW}/${SCENARIO}-${SEQ}
      --scenario-category ${SCENARIO}
      --runs ${RUNS}
    depends_on:
      ncap_renderer:
        condition: service_started
      ncap_model:
        condition: service_started
    links:
      - "ncap_renderer:renderer"
      - "ncap_model:model"
    shm_size: "40gb"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ["${NCAP_GPUS}"]
